#+TITLE: Experiment Log
Each bitstream will produce 4 results: UnixBench, NPB and also performance counters will be measured in each case:
* Baseline bitstream
:PROPERTIES:
:ID:       d2932afd-bb0d-4d36-9f4f-4ee70c8ff9ee
:END:
This bitstream is the bitstream at the end of the [[https://pages.saclay.inria.fr/nicolas.derumigny/COMPAS-Tutorial.html][COMPAS 2025 tutorial]] with performance counters enabled at: ~/cva6/core/include/cv64a6_imafdch_sv39_config_pkg.sv

#+begin_src bash
   localparam CVA6ConfigPerfCounterEn = 1;
#+end_src

** Project Summary
*** Implementation Utilization
#+begin_src jupyter-python :results output drawer :exports results
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

# ==========================================
# 1. CONFIGURATION
# ==========================================
REPORT_PATH = "./bitstreams/SoC_wrapper_utilization_placed_base.rpt"

# ==========================================
# 2. PARSER LOGIC
# ==========================================

def parse_vivado_report_full(content):
    """
    Scans the report and extracts specific keys into a dictionary.
    """
    data = {}

    # Map: Label for Graph -> Text in Report
    target_map = {
        'LUT': 'Slice LUTs',
        'LUTRAM': 'LUT as Memory',
        'FF': 'Slice Registers',
        'BRAM': 'Block RAM Tile',
        'DSP': 'DSPs',
        'I/O': 'Bonded IOB',
        'BUFG': 'BUFGCTRL',
        'MMCM': 'MMCME2_ADV'
    }

    lines = content.split('\n')

    for line in lines:
        line = line.strip()
        if line.startswith('|'):
            parts = [x.strip() for x in line.split('|') if x.strip()]
            if len(parts) >= 2:
                row_name = parts[0].replace('*', '')
                row_val_str = parts[1]

                for user_label, vivado_key in target_map.items():
                    if row_name == vivado_key:
                        try:
                            data[user_label] = float(row_val_str)
                        except ValueError:
                            pass

    return data

# ==========================================
# 3. VISUALIZATION
# ==========================================

# 1. Load Data
if os.path.exists(REPORT_PATH):
    print(f"\n✅ Reading report from: {REPORT_PATH}")
    with open(REPORT_PATH, 'r') as f:
        content = f.read()
else:
    print(f"⚠️ File not found at {REPORT_PATH}. Using Sample Data.")
    content = SAMPLE_REPORT_DATA

# 2. Parse and Create DataFrame
metrics = parse_vivado_report_full(content)

# Specific order requested
order = ['MMCM', 'BUFG', 'I/O', 'DSP', 'BRAM', 'FF', 'LUTRAM', 'LUT']

df = pd.DataFrame([
    {'Resource': k, 'Count': metrics.get(k, 0)}
    for k in order
])

# 3. Display Table (The requested change)
# print("\n--- Absolute Resource Usage ---")
# Using Pandas styling for a cleaner look in Jupyter
# display(df.style.background_gradient(subset=['Count'], cmap='Blues'))

# 4. Plot Graph
sns.set_theme(style="whitegrid")
plt.figure(figsize=(12, 6))

ax = sns.barplot(
    data=df,
    x='Resource',
    y='Count',
    hue='Resource',
    palette='viridis'
)

ax.set_yscale("log") # Log Scale
plt.title('CVA6 FPGA Resource Usage (Absolute Count)', fontsize=16)
plt.ylabel('Count (Log Scale)', fontsize=12)
plt.xlabel('')

# Add labels
for i, p in enumerate(ax.patches):
    height = p.get_height()
    if height > 0:
        val_text = f"{int(height)}" if height.is_integer() else f"{height}"
        ax.text(p.get_x() + p.get_width() / 2., height * 1.1,
                val_text,
                ha="center", va="bottom", fontsize=11, fontweight='bold')

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
:results:
#+begin_example
✅ Reading report from: ./bitstreams/SoC_wrapper_utilization_placed_base.rpt
#+end_example
[[file:./.ob-jupyter/80f69f1fc27fac1f504bac7de189b99ab81f522b.png]]
:end:

*** Implementation Timing
#+begin_src jupyter-python :results output drawer :exports results
import pandas as pd
import os

# ==========================================
# 1. CONFIGURATION
# ==========================================
TIMING_REPORT_PATH = "./bitstreams/SoC_wrapper_timing_summary_routed_base.rpt"

# ==========================================
# 2. PARSER LOGIC
# ==========================================

def parse_timing_report(content):
    data = {}
    lines = content.split('\n')

    # State flags
    header_found = False

    for line in lines:
        # Detect the table header row
        if "WNS(ns)" in line and "WHS(ns)" in line:
            header_found = True
            continue

        # Parse the data row (usually the first non-empty line after dashes)
        if header_found and line.strip() and not line.strip().startswith('-'):
            parts = line.split()

            # Based on standard Vivado report columns:
            # Col 0: WNS (Setup)
            # Col 4: WHS (Hold)
            try:
                wns = float(parts[0])
                whs = float(parts[4])

                data['Metric'] = ['WNS (Setup)', 'WHS (Hold)']
                data['Value (ns)'] = [wns, whs]

            except (ValueError, IndexError):
                pass

            break # We only need the summary row

    return pd.DataFrame(data)

# ==========================================
# 3. EXECUTION
# ==========================================

# 1. Load
if os.path.exists(TIMING_REPORT_PATH):
    print(f"✅ Reading timing report from: {TIMING_REPORT_PATH}")
    with open(TIMING_REPORT_PATH, 'r') as f:
        content = f.read()
else:
    print(f"⚠️ File not found at {TIMING_REPORT_PATH}. Using Sample Data.")
    content = SAMPLE_TIMING_DATA

# 2. Parse
df_timing = parse_timing_report(content)

# 3. Display
print("\n--- Timing Summary ---")

# Styling: Red if negative (Time Violation), Green if positive (Safe)
def style_slack(val):
    color = 'red' if val < 0 else 'green'
    weight = 'bold'
    return f'color: {color}; font-weight: {weight}'

# Display with 3 decimal places
format_dict = {'Value (ns)': '{:.3f}'}

display(df_timing.style.format(format_dict).map(style_slack, subset=['Value (ns)']).hide(axis="index"))
#+end_src

#+RESULTS:
:results:
#+begin_example✅ Reading timing report from: ./bitstreams/SoC_wrapper_timing_summary_routed_base.rpt

--- Timing Summary ---
#+end_example
| Metric      | Value (ns) |
|-------------+------------|
| WNS (Setup) | 1.218      |
| WHS (Hold)  | 0.051      |
:end:

*** File locations
**** Bitstream
[[./bitstreams/baseline.bit]]
**** Implementation utilization report
[[./bitstreams/SoC_wrapper_utilization_placed_base.rpt]]
**** Implementation timing report
[[./bitstreams/SoC_wrapper_timing_summary_routed_base.rpt]]
**** Implementation power report
[[./bitstreams/SoC_wrapper_power_routed_base.rpt]]
** UnixBench
Experiment metadata
[[./runs/UnixBench/unixbench_19700101_064547_base.txt]]

#+begin_src jupyter-python :results output drawer :exports results
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

# ==========================================
# 1. CONFIGURATION
# ==========================================
LOG_FILE_PATH = "./runs/UnixBench/unixbench_19700101_064547_base.txt"
FPGA_CLOCK_HZ = 50_000_000  # 50 MHz

# ==========================================
# 2. PARSER LOGIC
# ==========================================
def load_data(path):
    if os.path.exists(path):
        print(f"\n✅ Loading data from: {path}")
        with open(path, "r", encoding='utf-8', errors='ignore') as f:
            return f.read()
    else:
        print(f"⚠️ File not found at {path}. Using Sample Data.")
        return SAMPLE_DATA

def parse_unixbench_log(raw_text):
    data = []
    current_test = {}
    in_test = False

    lines = raw_text.split('\n')

    for line in lines:
        line = line.strip()

        # 1. Detect Start
        if ">>>BEGIN_TEST" in line:
            test_name = line.split("|")[1]
            current_test = {
                'Test': test_name,
                'Label': test_name.replace('Arithmetic_', 'Arith ').replace('Syscall_', 'Sys ').replace('UB_', ''),
                'Category': 'Other',
                'Instructions': 0,
                'Cycles': 0,
                'IPC': 0.0,
                'Score': 0.0,
                'Unit': 'N/A',
                'Time_s': 0.0
            }

            # Categorize
            name = current_test['Test']
            if 'Arith' in name or 'Dhrystone' in name or 'Register' in name:
                current_test['Category'] = 'Integer / ALU'
            elif 'Whetstone' in name or 'Double' in name:
                current_test['Category'] = 'Float / FPU'
            else:
                current_test['Category'] = 'System / OS'

            in_test = True
            continue

        if in_test:
            # 2. Parse PAPI Headers
            if "[PAPI] Instructions:" in line:
                current_test['Instructions'] = int(line.split(":")[1].strip())
            elif "[PAPI] Cycles:" in line:
                current_test['Cycles'] = int(line.split(":")[1].strip())
            elif "[PAPI] IPC:" in line:
                current_test['IPC'] = float(line.split(":")[1].strip())

            # 3. Parse Scores
            elif line.startswith("COUNT|"):
                parts = line.split("|")
                try:
                    current_test['Score'] = float(parts[1])
                    current_test['Unit'] = parts[3].strip()
                except IndexError:
                    pass

            # 4. Detect End
            elif ">>>END_TEST" in line:
                # Calculate Time from Cycles
                if current_test['Cycles'] > 0:
                    current_test['Time_s'] = current_test['Cycles'] / FPGA_CLOCK_HZ

                data.append(current_test)
                in_test = False

    return pd.DataFrame(data)

# ==========================================
# 3. EXECUTION & VISUALIZATION
# ==========================================
log_content = load_data(LOG_FILE_PATH)
df = parse_unixbench_log(log_content)

if not df.empty:
    # 1. Visualization (IPC)
    sns.set_theme(style="whitegrid")
    plt.figure(figsize=(12, 6))

    sns.barplot(
        data=df.sort_values('IPC', ascending=False),
        x='IPC', y='Label', hue='Category', dodge=False, palette='viridis'
    )
    plt.title('CVA6 Architectural Efficiency (UnixBench IPC)', fontsize=14)
    plt.xlabel('Instructions Per Cycle')
    plt.xlim(0, 0.7)
    plt.legend(title='Category', loc='lower right')
    plt.tight_layout()
    plt.show()

    # 2. Detailed Data Table (Now with Time & Cycles)
    print("\n=== UnixBench Results (Detailed) ===")

    # Selecting ALL important columns
    display_cols = ['Label', 'Category', 'IPC', 'Instructions', 'Cycles', 'Time_s', 'Score', 'Unit']

    # Display with gradient on IPC
    display(df[display_cols].style.background_gradient(subset=['IPC'], cmap='RdYlGn'))

    # 3. Export CSV
    csv_filename = "unixbench_results_final.csv"
    df[display_cols].to_csv(csv_filename, index=False)
    print(f"\n✅ Data exported to {csv_filename}")

else:
    print("❌ No valid data found.")
#+end_src

#+RESULTS:
:results:
#+begin_example
✅ Loading data from: ./runs/UnixBench/unixbench_19700101_064547_base.txt
#+end_example
[[file:./.ob-jupyter/5dc1bd1f49c23865a5455de0268ca0612b7b5dc7.png]]
#+begin_example

=== UnixBench Results (Detailed) ===
#+end_example
|    | Label             | Category      | IPC      | Instructions | Cycles    | Time_s   | Score           | Unit  |
|----+-------------------+---------------+----------+--------------+-----------+----------+-----------------+-------|
| 0  | Arith Overhead    | Integer / ALU | 0.388300 | 96160360     | 247619804 | 4.952396 | 22607716.000000 | lps   |
| 1  | Arith Register    | Integer / ALU | 0.568500 | 140705146    | 247489519 | 4.949790 | 658341.000000   | lps   |
| 2  | Arith Short       | Integer / ALU | 0.569000 | 140859170    | 247565240 | 4.951305 | 659170.000000   | lps   |
| 3  | Arith Int         | Integer / ALU | 0.568700 | 140769091    | 247527031 | 4.950541 | 658720.000000   | lps   |
| 4  | Dhrystone         | Integer / ALU | 0.447600 | 81389671     | 181828082 | 3.636562 | 259837.000000   | lps   |
| 5  | Arith Double      | Integer / ALU | 0.568800 | 140675372    | 247333099 | 4.946662 | 658256.000000   | lps   |
| 6  | Whetstone         | Float / FPU   | 0.410800 | 103499392    | 251932322 | 5.038646 | 19.449000       | MWIPS |
| 7  | Sys Mix           | System / OS   | 0.174900 | 43254593     | 247366131 | 4.947323 | 22651.000000    | lps   |
| 8  | Sys GetPID        | System / OS   | 0.225900 | 55509267     | 245775079 | 4.915502 | 205011.000000   | lps   |
| 9  | Sys Exec          | System / OS   | 0.119100 | 2620492      | 21995437  | 0.439909 | 20.000000       | lps   |
| 10 | Pipe_Throughput   | System / OS   | 0.140400 | 34742090     | 247521360 | 4.950427 | 8840.000000     | lps   |
| 11 | Context_Switching | System / OS   | 0.116900 | 14197502     | 121473123 | 2.429462 | 856.000000      | lps   |
#+begin_example

✅ Data exported to unixbench_results_final.csv
#+end_example
:end:

** NAS Parallel Benchmark
Experiment metadata
[[./runs/NPB/NPB_19700101_002113_base.txt]]

#+begin_src jupyter-python :results output drawer :exports results
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import re

# ==========================================
# 1. CONFIGURATION
# ==========================================
LOG_FILE_PATH = "runs/NPB/NPB_19700101_002113_base.txt"
FPGA_CLOCK_HZ = 50_000_000

# ==========================================
# 2. PARSER LOGIC
# ==========================================
def load_data(path):
    if os.path.exists(path):
        print(f"\n✅ Loading data from: {path}")
        with open(path, "r", encoding='utf-8', errors='ignore') as f:
            return f.read()
    else:
        print(f"⚠️ File not found at {path}. Using Sample Data.")
        return SAMPLE_DATA

def parse_npb_log(raw_text):
    data = []
    current_test = {}
    in_test = False

    size_pattern = re.compile(r"Size:\s+(\d+)")
    iter_pattern = re.compile(r"Iterations:\s+(\d+)")

    lines = raw_text.split('\n')

    for line in lines:
        line = line.strip()

        if ">>>BEGIN_TEST" in line:
            test_name = line.split("|")[1]
            current_test = {
                'Test': test_name,
                'Label': test_name.replace('NPB_', '').replace('_S', '').replace('_W', ''),
                'Category': 'Other',
                'Instructions': 0,
                'Cycles': 0,
                'IPC': 0.0,
                'Score': 0.0,
                'Time_s': 0.0,
                'Method': 'Reported',
                'Work_Keys': 0,
                'Work_Iter': 0
            }

            lbl = current_test['Label']
            if lbl == 'EP': current_test['Category'] = 'Compute Bound'
            elif lbl in ['IS', 'CG', 'MG']: current_test['Category'] = 'Memory Bound'
            elif lbl in ['FT', 'LU', 'SP', 'BT']: current_test['Category'] = 'Mixed / Streaming'

            in_test = True
            continue

        if in_test:
            if "Size:" in line:
                m = size_pattern.search(line)
                if m: current_test['Work_Keys'] = int(m.group(1))
            if "Iterations:" in line:
                m = iter_pattern.search(line)
                if m: current_test['Work_Iter'] = int(m.group(1))

            if "[PAPI] Instructions:" in line:
                current_test['Instructions'] = int(line.split(":")[1].strip())
            elif "[PAPI] Cycles:" in line:
                current_test['Cycles'] = int(line.split(":")[1].strip())
            elif "[PAPI] IPC:" in line:
                current_test['IPC'] = float(line.split(":")[1].strip())

            elif "Mop/s total" in line:
                try:
                    val_str = line.split("=")[1].strip()
                    if val_str.lower() in ['inf', 'nan']:
                        current_test['Score'] = 0.0
                    else:
                        current_test['Score'] = float(val_str)
                except:
                    pass

            elif ">>>END_TEST" in line:
                # Calculate Time from Cycles (Most Accurate)
                if current_test['Cycles'] > 0:
                    current_test['Time_s'] = current_test['Cycles'] / FPGA_CLOCK_HZ

                # Repair IS Score
                if current_test['Label'] == 'IS' and current_test['Score'] == 0.0:
                    keys = current_test['Work_Keys']
                    iters = current_test['Work_Iter']
                    time_s = current_test['Time_s']

                    if keys > 0 and time_s > 0:
                        total_ops = keys * iters
                        new_score = (total_ops / 1_000_000.0) / time_s
                        current_test['Score'] = new_score
                        current_test['Method'] = 'Recalculated'

                data.append(current_test)
                in_test = False

    return pd.DataFrame(data)

# ==========================================
# 3. EXECUTION & DISPLAY
# ==========================================
log_content = load_data(LOG_FILE_PATH)
df = parse_npb_log(log_content)

if not df.empty:
    # 1. Visualization
    sns.set_theme(style="whitegrid")
    fig, axes = plt.subplots(2, 1, figsize=(12, 10))

    # Plot IPC
    sns.barplot(
        data=df.sort_values('IPC', ascending=False),
        x='IPC', y='Label', hue='Category', dodge=False, palette='viridis', ax=axes[0]
    )
    axes[0].set_title('CVA6 Architectural Efficiency (IPC)', fontsize=14)
    axes[0].set_xlabel('Instructions Per Cycle')
    axes[0].set_xlim(0, 0.4)

    # Plot Score
    sns.barplot(
        data=df.sort_values('Score', ascending=False),
        x='Score', y='Label', hue='Category', dodge=False, palette='magma', ax=axes[1]
    )
    axes[1].set_title('Performance Score (Mop/s)', fontsize=14)
    axes[1].set_xlabel('Million Operations Per Second')

    plt.tight_layout()
    plt.show()

    # 2. Detailed Data Table (With Instructions & Cycles)
    print("\n=== NAS Parallel Benchmark Results ===")

    # Selecting ALL important columns
    display_cols = ['Label', 'Category', 'IPC', 'Instructions', 'Cycles', 'Time_s', 'Score', 'Method']

    # Display with gradient on IPC to highlight efficiency
    display(df[display_cols].style.background_gradient(subset=['IPC'], cmap='RdYlGn'))

    # 3. Export to CSV
    # csv_filename = "npb_results_final.csv"
    # df[display_cols].to_csv(csv_filename, index=False)
    # print(f"\n✅ Data exported to {csv_filename}")

else:
    print("❌ No valid data found.")
#+end_src

#+RESULTS:
:results:
#+begin_example
✅ Loading data from: runs/NPB/NPB_19700101_002113_base.txt
#+end_example
[[file:./.ob-jupyter/7da0c1dac06256c0f67247c031c3cb99bb9f8332.png]]
#+begin_example

=== NAS Parallel Benchmark Results ===
#+end_example
|   | Label | Category          | IPC      | Instructions | Cycles     | Time_s     | Score    | Method       |
|---+-------+-------------------+----------+--------------+------------+------------+----------+--------------|
| 0 | EP    | Compute Bound     | 0.296600 | 2091494568   | 7051840628 | 141.036813 | 0.120000 | Reported     |
| 1 | IS    | Memory Bound      | 0.214400 | 7563104      | 35267690   | 0.705354   | 0.929122 | Recalculated |
| 2 | CG    | Memory Bound      | 0.168000 | 355640156    | 2117107268 | 42.342145  | 0.780000 | Reported     |
| 3 | MG    | Memory Bound      | 0.192600 | 33926533     | 176124045  | 3.522481   | 1.070000 | Reported     |
| 4 | FT    | Mixed / Streaming | 0.159800 | 586395665    | 3670402373 | 73.408047  | 1.190000 | Reported     |
| 5 | BT    | Mixed / Streaming | 0.209600 | 549479226    | 2621152419 | 52.423048  | 2.160000 | Reported     |
| 6 | SP    | Mixed / Streaming | 0.181900 | 357024090    | 1962313810 | 39.246276  | 1.220000 | Reported     |
| 7 | LU    | Mixed / Streaming | 0.230400 | 200137752    | 868497471  | 17.369949  | 2.910000 | Reported     |
:end:
