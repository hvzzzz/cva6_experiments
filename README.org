#+TITLE: Experiment Log
Each bitstream will produce 4 results: UnixBench, NPB and also performance counters will be measured in each case:
* Baseline bitstream
:PROPERTIES:
:ID:       d2932afd-bb0d-4d36-9f4f-4ee70c8ff9ee
:END:
This bitstream is the bitstream at the end of the [[https://pages.saclay.inria.fr/nicolas.derumigny/COMPAS-Tutorial.html][COMPAS 2025 tutorial]] with performance counters enabled at: ~/cva6/core/include/cv64a6_imafdch_sv39_config_pkg.sv

#+begin_src bash
   localparam CVA6ConfigPerfCounterEn = 1;
#+end_src

*** Project Summary

[[./images/Screenshot from 2025-12-07 13-42-17.png]]

*** Bitstream location
[[./bitstreams/baseline.bit]]
*** Implementation utilization
[[./bitstreams/SoC_wrapper_utilization_placed_base.rpt]]
*** Implementation timing
[[./bitstreams/SoC_wrapper_timing_summary_routed_base.rpt]]
*** Implementation power
[[./bitstreams/SoC_wrapper_power_routed_base.rpt]]
** UnixBench
Experiment metadata
[[./runs/UnixBench/unixbench_19700101_064547_base.txt]]

#+begin_src jupyter-python :exports results
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

# ==========================================
# 1. CONFIGURATION
# ==========================================

# Path to your specific log file
LOG_FILE_PATH = "./runs/UnixBench/unixbench_19700101_064547_base.txt"


# ==========================================
# 2. DATA LOADING & PARSING
# ==========================================

def load_data(path):
    if os.path.exists(path):
        print(f"✅ Loading data from: {path}")
        with open(path, "r") as f:
            return f.read()
    else:
        print(f"⚠️ File not found at {path}. Using Sample Data for demonstration.")
        return SAMPLE_DATA

def parse_log_data(raw_text):
    data = []
    current_test = {}
    in_test = False

    lines = raw_text.split('\n')

    for line in lines:
        line = line.strip()

        # Detect Start of Test
        if ">>>BEGIN_TEST" in line:
            test_name = line.split("|")[1]
            current_test = {
                'Test': test_name,
                'Instructions': 0,
                'Cycles': 0,
                'IPC': 0.0,
                'Score': 0.0,
                'Unit': 'N/A',
                'Category': 'Other'
            }

            # Categorize for better plotting
            if 'Arith' in test_name or 'Dhrystone' in test_name or 'Register' in test_name:
                current_test['Category'] = 'Integer/ALU'
            elif 'Whetstone' in test_name or 'Double' in test_name:
                current_test['Category'] = 'Float/FPU'
            elif 'Syscall' in test_name or 'Context' in test_name or 'Pipe' in test_name:
                current_test['Category'] = 'System/OS'

            in_test = True
            continue

        if in_test:
            # Parse PAPI Headers
            if "[PAPI] Instructions:" in line:
                current_test['Instructions'] = int(line.split(":")[1].strip())
            elif "[PAPI] Cycles:" in line:
                current_test['Cycles'] = int(line.split(":")[1].strip())
            elif "[PAPI] IPC:" in line:
                current_test['IPC'] = float(line.split(":")[1].strip())

            # Parse UnixBench Scores (COUNT|score|...|unit)
            elif line.startswith("COUNT|"):
                parts = line.split("|")
                try:
                    current_test['Score'] = float(parts[1])
                    current_test['Unit'] = parts[3].strip()
                except IndexError:
                    pass

            # Parse Whetstone specific format (MWIPS at end of line)
            elif "MWIPS" in line and "COUNT" not in line:
                 parts = line.split()
                 if len(parts) >= 2:
                     try:
                         # Usually formatted like: MWIPS   19.449   9.769
                         current_test['Score'] = float(parts[1])
                         current_test['Unit'] = 'MWIPS'
                     except ValueError:
                         pass

            # Detect End
            elif ">>>END_TEST" in line:
                # Cleanup Label name
                current_test['Label'] = current_test['Test'].replace('Arithmetic_', '').replace('Syscall_', '').replace('UB_', '')
                data.append(current_test)
                in_test = False

    return pd.DataFrame(data)

# Load and Parse
log_content = load_data(LOG_FILE_PATH)
df = parse_log_data(log_content)

# ==========================================
# 3. VISUALIZATION
# ==========================================

if not df.empty:
    # Set Style
    sns.set_theme(style="whitegrid")
    plt.rcParams.update({'figure.figsize': (14, 10), 'font.size': 12})

    fig, axes = plt.subplots(2, 1, height_ratios=[1, 1.2])

    # --- PLOT 1: Efficiency (IPC) ---
    sns.barplot(
        data=df.sort_values('IPC', ascending=False),
        x='IPC',
        y='Label',
        hue='Category',
        dodge=False,
        palette='viridis',
        ax=axes[0]
    )
    axes[0].set_title('CVA6 Architectural Efficiency (Instructions Per Cycle)', fontsize=16, pad=15)
    axes[0].set_xlabel('IPC (Higher is Better)')
    axes[0].set_ylabel('')
    axes[0].set_xlim(0, 0.7)
    axes[0].legend(title='Workload Type', loc='lower right')

    for container in axes[0].containers:
        axes[0].bar_label(container, fmt='%.2f', padding=3)

    # --- PLOT 2: Benchmark Scores ---
    sns.barplot(
        data=df.sort_values('Score', ascending=False),
        x='Score',
        y='Label',
        hue='Unit',
        dodge=False,
        palette='magma',
        ax=axes[1]
    )
    axes[1].set_xscale('log')
    axes[1].set_title('UnixBench Scores (Log Scale)', fontsize=16, pad=15)
    axes[1].set_xlabel('Score (Log Scale) - Note Different Units!')
    axes[1].set_ylabel('')
    axes[1].legend(title='Metric Unit', loc='lower right')

    for container in axes[1].containers:
        axes[1].bar_label(container, fmt='%.1e', padding=3)

    plt.tight_layout()
    plt.show()

    # --- DATA TABLE ---
    print("\n=== Parsed Benchmark Data ===")
    display_cols = ['Test', 'Category', 'IPC', 'Instructions', 'Score', 'Unit']
    # Use Pandas styling for Jupyter
    display(df[display_cols].style.background_gradient(subset=['IPC'], cmap='RdYlGn'))

else:
    print("❌ No valid test data found in the file.")
#+end_src

#+RESULTS:
:RESULTS:
: ✅ Loading data from: ./runs/UnixBench/unixbench_19700101_064547_base.txt
[[file:./.ob-jupyter/f8cc59f5363990aa4ce071645d4d01577b5be820.png]]
:
: === Parsed Benchmark Data ===
|    | Test                | Category    | IPC      | Instructions | Score           | Unit  |
|----+---------------------+-------------+----------+--------------+-----------------+-------|
| 0  | Arithmetic_Overhead | Integer/ALU | 0.388300 | 96160360     | 22607716.000000 | lps   |
| 1  | Arithmetic_Register | Integer/ALU | 0.568500 | 140705146    | 658341.000000   | lps   |
| 2  | Arithmetic_Short    | Integer/ALU | 0.569000 | 140859170    | 659170.000000   | lps   |
| 3  | Arithmetic_Int      | Integer/ALU | 0.568700 | 140769091    | 658720.000000   | lps   |
| 4  | Dhrystone           | Integer/ALU | 0.447600 | 81389671     | 259837.000000   | lps   |
| 5  | Arithmetic_Double   | Integer/ALU | 0.568800 | 140675372    | 658256.000000   | lps   |
| 6  | Whetstone           | Float/FPU   | 0.410800 | 103499392    | 19.449000       | MWIPS |
| 7  | Syscall_Mix         | System/OS   | 0.174900 | 43254593     | 22651.000000    | lps   |
| 8  | Syscall_GetPID      | System/OS   | 0.225900 | 55509267     | 205011.000000   | lps   |
| 9  | Syscall_Exec        | System/OS   | 0.119100 | 2620492      | 20.000000       | lps   |
| 10 | Pipe_Throughput     | System/OS   | 0.140400 | 34742090     | 8840.000000     | lps   |
| 11 | Context_Switching   | System/OS   | 0.116900 | 14197502     | 856.000000      | lps   |
:END:

: ✅ Loading data from: ./runs/UnixBench/unixbench_19700101_064547_base.txt
[[./.ob-jupyter/f8cc59f5363990aa4ce071645d4d01577b5be820.png]]
:
: === Parsed Benchmark Data ===
|    | Test                | Category    | IPC      | Instructions | Score           | Unit  |
|----+---------------------+-------------+----------+--------------+-----------------+-------|
| 0  | Arithmetic_Overhead | Integer/ALU | 0.388300 | 96160360     | 22607716.000000 | lps   |
| 1  | Arithmetic_Register | Integer/ALU | 0.568500 | 140705146    | 658341.000000   | lps   |
| 2  | Arithmetic_Short    | Integer/ALU | 0.569000 | 140859170    | 659170.000000   | lps   |
| 3  | Arithmetic_Int      | Integer/ALU | 0.568700 | 140769091    | 658720.000000   | lps   |
| 4  | Dhrystone           | Integer/ALU | 0.447600 | 81389671     | 259837.000000   | lps   |
| 5  | Arithmetic_Double   | Integer/ALU | 0.568800 | 140675372    | 658256.000000   | lps   |
| 6  | Whetstone           | Float/FPU   | 0.410800 | 103499392    | 19.449000       | MWIPS |
| 7  | Syscall_Mix         | System/OS   | 0.174900 | 43254593     | 22651.000000    | lps   |
| 8  | Syscall_GetPID      | System/OS   | 0.225900 | 55509267     | 205011.000000   | lps   |
| 9  | Syscall_Exec        | System/OS   | 0.119100 | 2620492      | 20.000000       | lps   |
| 10 | Pipe_Throughput     | System/OS   | 0.140400 | 34742090     | 8840.000000     | lps   |
| 11 | Context_Switching   | System/OS   | 0.116900 | 14197502     | 856.000000      | lps   |


** NAS Parallel Benchmark
Experiment metadata
[[./runs/NPB/NPB_19700101_081823_base.txt]]

#+begin_src jupyter-python :exports results
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

# ==========================================
# 1. CONFIGURATION
# ==========================================

LOG_FILE_PATH = "runs/NPB/NPB_19700101_081823_base.txt"

# Sample data fallback (just in case)
SAMPLE_DATA = """
>>>BEGIN_TEST|NPB_EP_S
[PAPI] Instructions: 2091610366
[PAPI] Cycles:       7052575499
[PAPI] IPC:          0.2966
Mop/s total      =                    0.12
>>>END_TEST
>>>BEGIN_TEST|NPB_CG_S
[PAPI] Instructions: 355809507
[PAPI] Cycles:       2125967585
[PAPI] IPC:          0.1674
Mop/s total      =                    0.78
>>>END_TEST
"""

# ==========================================
# 2. PARSING LOGIC
# ==========================================

def load_data(path):
    if os.path.exists(path):
        print(f"✅ Loading data from: {path}")
        with open(path, "r", encoding='utf-8', errors='ignore') as f:
            return f.read()
    else:
        print(f"⚠️ File not found at {path}. Using Sample Data.")
        return SAMPLE_DATA

def parse_npb_log(raw_text):
    data = []
    current_test = {}
    in_test = False

    lines = raw_text.split('\n')

    for line in lines:
        line = line.strip()

        if ">>>BEGIN_TEST" in line:
            test_name = line.split("|")[1]
            current_test = {
                'Test': test_name,
                'Label': test_name.replace('NPB_', '').replace('_S', ''), # Clean name
                'Instructions': 0,
                'Cycles': 0,
                'IPC': 0.0,
                'Score': 0.0,
                'Category': 'Other'
            }

            # Categorize based on workload type
            label = current_test['Label']
            if label == 'EP':
                current_test['Category'] = 'Compute Bound'
            elif label in ['IS', 'CG', 'MG']:
                current_test['Category'] = 'Memory Bound'
            elif label in ['FT', 'LU', 'SP', 'BT']:
                current_test['Category'] = 'Mixed / Streaming'

            in_test = True
            continue

        if in_test:
            # Parse PAPI
            if "[PAPI] Instructions:" in line:
                current_test['Instructions'] = int(line.split(":")[1].strip())
            elif "[PAPI] Cycles:" in line:
                current_test['Cycles'] = int(line.split(":")[1].strip())
            elif "[PAPI] IPC:" in line:
                current_test['IPC'] = float(line.split(":")[1].strip())

            # Parse Score (Mop/s)
            elif "Mop/s total" in line:
                try:
                    # Format: Mop/s total      =                    2.15
                    parts = line.split("=")
                    current_test['Score'] = float(parts[1].strip())
                except:
                    pass

            # Detect End
            elif ">>>END_TEST" in line:
                # Handle IS crash if present
                if current_test['IPC'] == 0 and current_test['Cycles'] == 0:
                    current_test['Label'] += " (Failed)"

                data.append(current_test)
                in_test = False

    return pd.DataFrame(data)

# Load
log_content = load_data(LOG_FILE_PATH)
df = parse_npb_log(log_content)

# Filter out failed tests (like IS if it segfaulted)
df = df[df['Cycles'] > 0]

# ==========================================
# 3. VISUALIZATION
# ==========================================

if not df.empty:
    sns.set_theme(style="whitegrid")
    plt.rcParams.update({'figure.figsize': (14, 10), 'font.size': 12})

    fig, axes = plt.subplots(2, 1, height_ratios=[1, 1])

    # --- PLOT 1: Efficiency (IPC) ---
    sns.barplot(
        data=df.sort_values('IPC', ascending=False),
        x='IPC',
        y='Label',
        hue='Category',
        dodge=False,
        palette='viridis',
        ax=axes[0]
    )
    axes[0].set_title('CVA6 Performance on NPB Class S (IPC)', fontsize=16, pad=15)
    axes[0].set_xlabel('Instructions Per Cycle (Higher is Better)')
    axes[0].set_ylabel('')
    axes[0].legend(title='Workload Type', loc='lower right')
    axes[0].set_xlim(0, 0.4) # Adjust limit based on max value (EP is ~0.3)

    for container in axes[0].containers:
        axes[0].bar_label(container, fmt='%.3f', padding=3)

    # --- PLOT 2: MFLOPS Scores ---
    sns.barplot(
        data=df.sort_values('Score', ascending=False),
        x='Score',
        y='Label',
        hue='Category',
        dodge=False,
        palette='magma',
        ax=axes[1]
    )
    axes[1].set_title('Absolute Performance (Mop/s)', fontsize=16, pad=15)
    axes[1].set_xlabel('Million Operations Per Second')
    axes[1].set_ylabel('')
    axes[1].legend(title='Workload Type', loc='lower right')

    for container in axes[1].containers:
        axes[1].bar_label(container, fmt='%.2f', padding=3)

    plt.tight_layout()
    plt.show()

    # --- DATA TABLE ---
    print("\n=== NAS Parallel Benchmark Results ===")
    display_cols = ['Label', 'Category', 'IPC', 'Instructions', 'Cycles', 'Score']
    display(df[display_cols].style.background_gradient(subset=['IPC'], cmap='RdYlGn'))

else:
    print("❌ No valid data found. Check the log file path.")
#+end_src

#+RESULTS:
:RESULTS:
: ✅ Loading data from: runs/NPB/NPB_19700101_081823_base.txt
[[file:./.ob-jupyter/d551c1b9487672ade4da408129495ec5f7d8f13e.png]]
:
: === NAS Parallel Benchmark Results ===
|   | Label | Category          | IPC      | Instructions | Cycles     | Score    |
|---+-------+-------------------+----------+--------------+------------+----------|
| 0 | EP    | Compute Bound     | 0.296600 | 2091610366   | 7052575499 | 0.120000 |
| 2 | CG    | Memory Bound      | 0.167400 | 355809507    | 2125967585 | 0.780000 |
| 3 | MG    | Memory Bound      | 0.193000 | 33938262     | 175850655  | 1.070000 |
| 4 | FT    | Mixed / Streaming | 0.159500 | 586546054    | 3678139437 | 1.190000 |
| 5 | BT    | Mixed / Streaming | 0.209400 | 549647248    | 2625329283 | 2.150000 |
| 6 | SP    | Mixed / Streaming | 0.181100 | 357286022    | 1972775720 | 1.210000 |
| 7 | LU    | Mixed / Streaming | 0.230000 | 200279517    | 870961646  | 2.900000 |
:END:
