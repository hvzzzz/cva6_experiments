#+title: Plots
#+OPTIONS: tags:t
#+EXPORT_EXCLUDE_TAGS: noexport

* Cache sweep
#+begin_src jupyter-python :results output drawer :exports results
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os
import re
import numpy as np
from scipy.stats import gmean
import warnings

# Suppress warnings
warnings.filterwarnings("ignore")

# 1. Setup & Load
RESULTS_DIR = "/home/han4n/cva6_experiments/results"
BASELINE_FILE = os.path.join(RESULTS_DIR, "baseline_results.csv")
EXPERIMENT_FILE = os.path.join(RESULTS_DIR, "cache_sweep_benchmark_results.csv")

df_base = pd.read_csv(BASELINE_FILE)
df_exp = pd.read_csv(EXPERIMENT_FILE)

# 2. Merge & Calculate
df_base_clean = df_base[['suite', 'name', 'score']].rename(columns={'score': 'base_score'})
df_merged = pd.merge(df_exp, df_base_clean, on=['suite', 'name'], how='inner')
df_merged['speedup'] = df_merged['score'] / df_merged['base_score']

def extract_size(config_str):
    m = re.search(r'(\d+)k', str(config_str), re.IGNORECASE)
    if m: return int(m.group(1))
    return 0

df_merged['size_kb'] = df_merged['config'].apply(extract_size)
df_merged = df_merged.sort_values(by='size_kb')

# =============================================================================
# PLOT A: UnixBench Performance (The "System" Benchmarks)
# =============================================================================
plt.figure(figsize=(12, 6))
plt.rcParams['figure.dpi'] = 300
sns.set_theme(style="whitegrid")

# Filter Data
unix_data = df_merged[df_merged['suite'] == 'UnixBench']

chart = sns.barplot(
    data=unix_data,
    x="name",
    y="speedup",
    hue="config",
    palette="viridis"
)

# Formatting
plt.rc('text',usetex =True)
plt.rc('font',family = 'serif')
plt.axhline(1.0, color='red', linestyle='--', linewidth=2, label="Baseline")
plt.title("UnixBench Suite: Sensitivity to Cache Size", fontsize=16)
plt.ylabel("Speedup")
plt.xlabel("Benchmark Name")
plt.xticks(rotation=45, ha='right')
plt.ylim(0.96, 1.05)
plt.legend(title="Cache Config", bbox_to_anchor=(1.02, 1), loc='upper left')

plt.tight_layout()
plt.show()

# =============================================================================
# PLOT B: NPB Performance (The "Scientific" Benchmarks)
# =============================================================================
plt.figure(figsize=(12, 6))
plt.rcParams['figure.dpi'] = 300
sns.set_theme(style="whitegrid")

# Filter Data
npb_data = df_merged[df_merged['suite'] == 'NPB']

chart = sns.barplot(
    data=npb_data,
    x="name",
    y="speedup",
    hue="config",
    palette="viridis"
)

# Formatting
plt.rc('text',usetex =True)
plt.rc('font',family = 'serif')
plt.axhline(1.0, color='red', linestyle='--', linewidth=2, label="Baseline")
plt.title("NAS Parallel Benchmarks (NPB): Sensitivity to Cache Size", fontsize=16)
plt.ylabel("Speedup")
plt.xlabel("Benchmark Name")
plt.ylim(0.975, 1.13)
plt.legend(title="Cache Config", bbox_to_anchor=(1.02, 1), loc='upper left')

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
:results:
#+begin_example
#+end_example
[[file:./.ob-jupyter/f6f8b6ba39b3cce637ab0b32b3201fb7ca27cf7b.png]]
[[file:./.ob-jupyter/d2efbb1debc29a5c199a0bf8697c1b8149f6bb04.png]]
:end:
* Associativity sweep

#+begin_src jupyter-python :results output drawer :exports results
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os
import re
import warnings

# Suppress warnings
warnings.filterwarnings("ignore")

# 1. Setup & Load
RESULTS_DIR = "/home/han4n/cva6_experiments/results"
BASELINE_FILE = os.path.join(RESULTS_DIR, "baseline_results.csv")
EXPERIMENT_FILE = os.path.join(RESULTS_DIR, "associativity_sweep_benchmark_results.csv")

if not os.path.exists(EXPERIMENT_FILE):
    print(f"Error: Experiment file not found at {EXPERIMENT_FILE}")
    print("Did you run the scraping script for the Associativity Sweep?")
else:
    df_base = pd.read_csv(BASELINE_FILE)
    df_exp = pd.read_csv(EXPERIMENT_FILE)

    # 2. Merge & Calculate
    df_base_clean = df_base[['suite', 'name', 'score']].rename(columns={'score': 'base_score'})
    df_merged = pd.merge(df_exp, df_base_clean, on=['suite', 'name'], how='inner')
    df_merged['speedup'] = df_merged['score'] / df_merged['base_score']

    # 3. Sort by Associativity (Extract number from "1w", "2w")
    def extract_ways(config_str):
        # Look for a number at the start or embedded in the string
        m = re.search(r'(\d+)', str(config_str))
        if m: return int(m.group(1))
        return 0

    df_merged['ways'] = df_merged['config'].apply(extract_ways)
    df_merged = df_merged.sort_values(by='ways')

    # =============================================================================
    # PLOT A: UnixBench Performance
    # =============================================================================
    plt.figure(figsize=(12, 6))
    sns.set_theme(style="whitegrid")

    unix_data = df_merged[df_merged['suite'] == 'UnixBench']

    if not unix_data.empty:
        sns.barplot(
            data=unix_data,
            x="name",
            y="speedup",
            hue="config",
            palette="viridis"
        )
        plt.rc('text',usetex =True)
        plt.rc('font',family = 'serif')
        plt.rcParams['figure.dpi'] = 300
        plt.axhline(1.0, color='red', linestyle='--', linewidth=2, label="Baseline (4-way)")
        plt.title("UnixBench: Sensitivity to Cache Associativity", fontsize=16)
        plt.ylabel("Speedup")
        plt.xlabel("Benchmark Name")
        plt.xticks(rotation=45, ha='right')
        plt.ylim(0.98, 1.04)
        plt.legend(title="Associativity", bbox_to_anchor=(1.02, 1), loc='upper left')

        plt.tight_layout()
        plt.show()
    else:
        print("No UnixBench data found for Associativity sweep.")

    # =============================================================================
    # PLOT B: NPB Performance
    # =============================================================================
    plt.figure(figsize=(12, 6))
    sns.set_theme(style="whitegrid")

    npb_data = df_merged[df_merged['suite'] == 'NPB']

    if not npb_data.empty:
        sns.barplot(
            data=npb_data,
            x="name",
            y="speedup",
            hue="config",
            palette="viridis"
        )
        plt.rc('text',usetex =True)
        plt.rc('font',family = 'serif')
        plt.rcParams['figure.dpi'] = 300
        plt.axhline(1.0, color='red', linestyle='--', linewidth=2, label="Baseline (4-way)")
        plt.title("NPB: Sensitivity to Cache Associativity", fontsize=16)
        plt.ylabel("Speedup")
        plt.xlabel("Benchmark Name")
        plt.ylim(0.95, 1.13)
        plt.legend(title="Associativity", bbox_to_anchor=(1.02, 1), loc='upper left')

        plt.tight_layout()
        plt.show()
    else:
        print("No NPB data found for Associativity sweep.")
#+end_src

#+RESULTS:
:results:
#+begin_example
#+end_example
[[file:./.ob-jupyter/e49a03af9ddbe81b245dad8eac05f311980338b1.png]]
[[file:./.ob-jupyter/e10aec7e5d9487418d686e9cc525efb9f25e6d16.png]]
:end:
* BTB Size Sweep
#+begin_src jupyter-python :results output drawer :exports results
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os
import re
import warnings

# Suppress warnings
warnings.filterwarnings("ignore")

# 1. Setup & Load
RESULTS_DIR = "/home/han4n/cva6_experiments/results"
BASELINE_FILE = os.path.join(RESULTS_DIR, "baseline_results.csv")
EXPERIMENT_FILE = os.path.join(RESULTS_DIR, "btb_sweep_benchmark_results.csv")

if not os.path.exists(EXPERIMENT_FILE):
    print(f"Error: Experiment file not found at {EXPERIMENT_FILE}")
else:
    df_base = pd.read_csv(BASELINE_FILE)
    df_exp = pd.read_csv(EXPERIMENT_FILE)

    # 2. Merge & Calculate
    df_base_clean = df_base[['suite', 'name', 'score']].rename(columns={'score': 'base_score'})
    df_merged = pd.merge(df_exp, df_base_clean, on=['suite', 'name'], how='inner')
    df_merged['speedup'] = df_merged['score'] / df_merged['base_score']

    # 3. Sort by BTB Size (Extract number from "BTB8", "BTB32")
    def extract_btb_size(config_str):
        m = re.search(r'(\d+)', str(config_str))
        if m: return int(m.group(1))
        return 0

    df_merged['entries'] = df_merged['config'].apply(extract_btb_size)
    df_merged = df_merged.sort_values(by='entries')

    # =============================================================================
    # PLOT A: UnixBench Performance
    # =============================================================================
    plt.figure(figsize=(12, 6))
    sns.set_theme(style="whitegrid")

    unix_data = df_merged[df_merged['suite'] == 'UnixBench']

    if not unix_data.empty:
        sns.barplot(
            data=unix_data,
            x="name",
            y="speedup",
            hue="config",
            palette="viridis"
        )
        plt.rc('text',usetex =True)
        plt.rc('font',family = 'serif')
        plt.rcParams['figure.dpi'] = 300
        plt.axhline(1.0, color='red', linestyle='--', linewidth=2, label="Baseline (BTB 16)")
        plt.title("UnixBench: Sensitivity to BTB Size", fontsize=16)
        plt.ylabel("Speedup")
        plt.xlabel("Benchmark Name")
        plt.xticks(rotation=45, ha='right')
        plt.ylim(0.9, 1.035)
        plt.legend(title="BTB Entries", bbox_to_anchor=(1.02, 1), loc='upper left')

        plt.tight_layout()
        plt.show()
    else:
        print("No UnixBench data found for BTB sweep.")

    # =============================================================================
    # PLOT B: NPB Performance
    # =============================================================================
    plt.figure(figsize=(12, 6))
    sns.set_theme(style="whitegrid")

    npb_data = df_merged[df_merged['suite'] == 'NPB']

    if not npb_data.empty:
        sns.barplot(
            data=npb_data,
            x="name",
            y="speedup",
            hue="config",
            palette="viridis"
        )
        plt.rc('text',usetex =True)
        plt.rc('font',family = 'serif')
        plt.rcParams['figure.dpi'] = 300
        plt.axhline(1.0, color='red', linestyle='--', linewidth=2, label="Baseline (BTB 16)")
        plt.title("NPB: Sensitivity to BTB Size", fontsize=16)
        plt.ylabel("Speedup")
        plt.xlabel("Benchmark Name")
        plt.ylim(0.9, 1.15)
        plt.legend(title="BTB Entries", bbox_to_anchor=(1.02, 1), loc='upper left')

        plt.tight_layout()
        plt.show()
    else:
        print("No NPB data found for BTB sweep.")
#+end_src

#+RESULTS:
:results:
#+begin_example
#+end_example
[[file:./.ob-jupyter/65ddbbf18d13a43e0a49da41361aa1fdd9343c88.png]]
[[file:./.ob-jupyter/5f7c0101e6fd6e7d49b2a259a82e91b0f4813a78.png]]
:end:
* BHT Size Sweep
#+begin_src jupyter-python :results output drawer :exports results
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os
import re
import warnings

# Suppress warnings
warnings.filterwarnings("ignore")

# 1. Setup & Load
RESULTS_DIR = "/home/han4n/cva6_experiments/results"
BASELINE_FILE = os.path.join(RESULTS_DIR, "baseline_results.csv")
EXPERIMENT_FILE = os.path.join(RESULTS_DIR, "bht_sweep_benchmark_results.csv")

if not os.path.exists(EXPERIMENT_FILE):
    print(f"Error: Experiment file not found at {EXPERIMENT_FILE}")
else:
    df_base = pd.read_csv(BASELINE_FILE)
    df_exp = pd.read_csv(EXPERIMENT_FILE)

    # 2. Merge & Calculate
    df_base_clean = df_base[['suite', 'name', 'score']].rename(columns={'score': 'base_score'})
    df_merged = pd.merge(df_exp, df_base_clean, on=['suite', 'name'], how='inner')
    df_merged['speedup'] = df_merged['score'] / df_merged['base_score']

    # 3. Sort by BHT Entries (Extract number from "BHT32", "BHT128")
    def extract_bht_entries(config_str):
        m = re.search(r'(\d+)', str(config_str))
        if m: return int(m.group(1))
        return 0

    df_merged['entries'] = df_merged['config'].apply(extract_bht_entries)
    df_merged = df_merged.sort_values(by='entries')

    # =============================================================================
    # PLOT A: UnixBench Performance
    # =============================================================================
    plt.figure(figsize=(12, 6))
    sns.set_theme(style="whitegrid")

    unix_data = df_merged[df_merged['suite'] == 'UnixBench']

    if not unix_data.empty:
        sns.barplot(
            data=unix_data,
            x="name",
            y="speedup",
            hue="config",
            palette="viridis"
        )
        plt.rc('text',usetex =True)
        plt.rc('font',family = 'serif')
        plt.rcParams['figure.dpi'] = 300
        plt.axhline(1.0, color='red', linestyle='--', linewidth=2, label="Baseline (BHT 16)")
        plt.title("UnixBench: Sensitivity to BHT Size", fontsize=16)
        plt.ylabel("Speedup")
        plt.xlabel("Benchmark Name")
        plt.xticks(rotation=45, ha='right')
        plt.ylim(0.96, 1.03)
        plt.legend(title="BHT Entries", bbox_to_anchor=(1.02, 1), loc='upper left')

        plt.tight_layout()
        plt.show()
    else:
        print("No UnixBench data found for BHT sweep.")

    # =============================================================================
    # PLOT B: NPB Performance
    # =============================================================================
    plt.figure(figsize=(12, 6))
    sns.set_theme(style="whitegrid")

    npb_data = df_merged[df_merged['suite'] == 'NPB']

    if not npb_data.empty:
        sns.barplot(
            data=npb_data,
            x="name",
            y="speedup",
            hue="config",
            palette="viridis"
        )
        plt.rc('text',usetex =True)
        plt.rc('font',family = 'serif')
        plt.rcParams['figure.dpi'] = 300
        plt.axhline(1.0, color='red', linestyle='--', linewidth=2, label="Baseline (BHT 16)")
        plt.title("NPB: Sensitivity to BHT Size", fontsize=16)
        plt.ylabel("Speedup")
        plt.xlabel("Benchmark Name")
        plt.ylim(0.95, 1.15)
        plt.legend(title="BHT Entries", bbox_to_anchor=(1.02, 1), loc='upper left')

        plt.tight_layout()
        plt.show()
    else:
        print("No NPB data found for BHT sweep.")
#+end_src

#+RESULTS:
:results:
#+begin_example
#+end_example
[[file:./.ob-jupyter/d219972593f28e3c0d5668d86d98504b273df20f.png]]
[[file:./.ob-jupyter/18a5d1d0167a3291995d2783f2ac5e7b328c89e0.png]]
:end:
* PAPI
#+begin_src jupyter-python :results output drawer :exports results
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os
import re
import warnings

warnings.filterwarnings("ignore")

# 1. Setup
RESULTS_DIR = "/home/han4n/cva6_experiments/results"
BASELINE_FILE = os.path.join(RESULTS_DIR, "baseline_results.csv")

# Define all your experiments to process in a loop
experiments = [
    {
        "title": "Cache Size Sweep",
        "filename": "cache_sweep_benchmark_results.csv",
        "baseline_label": "Baseline (4KB)",
        "regex": r'(\d+)k',
        "sort_col": "size_kb"
    },
    {
        "title": "Associativity Sweep",
        "filename": "associativity_sweep_benchmark_results.csv",
        "baseline_label": "Baseline (4-way)",
        "regex": r'(\d+)w',
        "sort_col": "ways"
    },
    {
        "title": "BTB Size Sweep",
        "filename": "btb_sweep_benchmark_results.csv",
        "baseline_label": "Baseline (BTB 16)",
        "regex": r'BTB(\d+)',
        "sort_col": "entries"
    },
    {
        "title": "BHT Size Sweep",
        "filename": "bht_sweep_benchmark_results.csv",
        "baseline_label": "Baseline (BHT 16)",
        "regex": r'BHT(\d+)',
        "sort_col": "entries"
    }
]

# Load Baseline once
if not os.path.exists(BASELINE_FILE):
    print("Error: Baseline file not found.")
else:
    df_base = pd.read_csv(BASELINE_FILE)
    df_base_clean = df_base[['suite', 'name', 'ipc']].rename(columns={'ipc': 'base_ipc'})

    # 2. Main Loop
    for exp in experiments:
        file_path = os.path.join(RESULTS_DIR, exp["filename"])

        if not os.path.exists(file_path):
            print(f"Skipping {exp['title']}: File not found.")
            continue

        print(f"Generating IPC Plots for: {exp['title']}...")
        df_exp = pd.read_csv(file_path)

        # Merge
        df_merged = pd.merge(df_exp, df_base_clean, on=['suite', 'name'], how='inner')

        # Calculate IPC Gain (Normalized Efficiency)
        df_merged['ipc_gain'] = df_merged['ipc'] / df_merged['base_ipc']

        # Extract sorting value
        def extract_val(config_str):
            m = re.search(exp['regex'], str(config_str), re.IGNORECASE)
            if m: return int(m.group(1))
            return 0

        df_merged[exp['sort_col']] = df_merged['config'].apply(extract_val)
        df_merged = df_merged.sort_values(by=exp['sort_col'])

        # Plotting (Separated by Suite for clarity)
        for suite in ['UnixBench', 'NPB']:
            subset = df_merged[df_merged['suite'] == suite]
            if subset.empty: continue

            plt.figure(figsize=(12, 5))
            sns.set_theme(style="whitegrid")

            sns.barplot(
                data=subset,
                x="name",
                y="ipc_gain",
                hue="config",
                palette="rocket" # Different color palette to distinguish from Speedup
            )
            plt.rc('text',usetex =True)
            plt.rc('font',family = 'serif')
            plt.rcParams['figure.dpi'] = 300
            plt.axhline(1.0, color='blue', linestyle='--', linewidth=2, label=exp['baseline_label'])
            plt.title(f"{exp['title']} - {suite}: IPC Efficiency Gain", fontsize=15)
            plt.ylabel("IPC Gain")
            plt.xlabel("Benchmark")
            plt.xticks(rotation=45, ha='right')
            plt.ylim(0.95, 1.05) # Focus on the changes
            plt.legend(title="Config", bbox_to_anchor=(1.02, 1), loc='upper left')

            plt.tight_layout()
            plt.show()
#+end_src

#+RESULTS:
:results:
#+begin_example
Generating IPC Plots for: Cache Size Sweep...
#+end_example
[[file:./.ob-jupyter/f91b6e8f22ebb06405c67f849b39780b8e4b9498.png]]
[[file:./.ob-jupyter/fca7a33f27129e5107f13c8450304b2ad67e82a3.png]]
#+begin_example
Generating IPC Plots for: Associativity Sweep...
#+end_example
[[file:./.ob-jupyter/90091a968f75ad164f441f2ec06bf2d8bca5882c.png]]
[[file:./.ob-jupyter/66fb8cff7cca5fb90ab104fb90e8fb229e38de66.png]]
#+begin_example
Generating IPC Plots for: BTB Size Sweep...
#+end_example
[[file:./.ob-jupyter/dd06e7f184dc7697038ba27fe486616edd261a2d.png]]
[[file:./.ob-jupyter/b6fc162a40c15e60251806e348d591d560c1d50e.png]]
#+begin_example
Generating IPC Plots for: BHT Size Sweep...
#+end_example
[[file:./.ob-jupyter/ace27f0780895604405ed0bc026fb8b44629cbcb.png]]
[[file:./.ob-jupyter/94afbd444e14269bb56c2dd507f88993eadcf43f.png]]
:end:

* Individual benchmarks

#+begin_src jupyter-python :results output drawer :exports results
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os
import re
import warnings

# --- 1. Global Setup ---
RESULTS_DIR = "/home/han4n/cva6_experiments/results"
PLOTS_DIR = os.path.join(RESULTS_DIR, "individual_benchmark_profiles")
os.makedirs(PLOTS_DIR, exist_ok=True)

# LaTeX & Style Settings
plt.rc('text', usetex=True)
plt.rc('font', family='serif')
plt.rcParams['figure.dpi'] = 300
warnings.filterwarnings("ignore")

# --- 2. Helper Functions ---
def prettify_config(conf):
    """Translates internal config names to descriptive publication labels."""
    if conf == "Ref": return "Baseline"

    # Cache: "IC/DC 16k" -> "16KB L1 Cache"
    m = re.search(r'IC/DC (\d+)k', str(conf), re.IGNORECASE)
    if m: return f"{m.group(1)}KB L1 Cache"

    # Associativity: "2w" -> "2-Way Assoc"
    m = re.search(r'^(\d+)w$', str(conf), re.IGNORECASE)
    if m: return f"{m.group(1)}-Way Assoc"

    # BTB: "BTB32" -> "32-Entry BTB"
    m = re.search(r'BTB(\d+)', str(conf), re.IGNORECASE)
    if m: return f"{m.group(1)}-Entry BTB"

    # BHT: "BHT32" -> "32-Entry BHT"
    m = re.search(r'BHT(\d+)', str(conf), re.IGNORECASE)
    if m: return f"{m.group(1)}-Entry BHT"

    return conf

def get_sort_value(config_str):
    m = re.search(r'(\d+)', str(config_str))
    if m: return int(m.group(1))
    return 0

def format_y_label(unit_str):
    """Converts raw unit strings into descriptive 'Quantity [Unit]' format."""
    unit_str = str(unit_str).strip()

    if unit_str == 'lps':
        return r"Throughput [Loops/s]"
    elif unit_str == 'Mop/s':
        return r"Throughput [Mop/s]"
    elif unit_str == 'KBps':
        return r"Data Rate [KB/s]"
    elif unit_str == 'MWIPS':
        return r"Processing Speed [MWIPS]"
    else:
        # Fallback for unknown units
        return fr"{Score [{unit_str}]}"

# --- 3. Data Loading & Merging ---
sources = [
    {"name": "Baseline",      "file": "baseline_results.csv",                  "color": "gray"},
    {"name": "Cache Size",    "file": "cache_sweep_benchmark_results.csv",     "color": "dodgerblue"},
    {"name": "Associativity", "file": "associativity_sweep_benchmark_results.csv", "color": "forestgreen"},
    {"name": "BTB Size",      "file": "btb_sweep_benchmark_results.csv",       "color": "darkorange"},
    {"name": "BHT Size",      "file": "bht_sweep_benchmark_results.csv",       "color": "purple"},
]

df_master = pd.DataFrame()
for src in sources:
    file_path = os.path.join(RESULTS_DIR, src["file"])
    if os.path.exists(file_path):
        temp_df = pd.read_csv(file_path)
        temp_df['sweep_type'] = src["name"]
        if src["name"] == "Baseline":
            temp_df['config'] = "Ref"
        df_master = pd.concat([df_master, temp_df], ignore_index=True)

# Identify all benchmarks
benchmarks = df_master['name'].unique()
palette = {src["name"]: src["color"] for src in sources}

print(f"Generating publication-ready images for {len(benchmarks)} benchmarks...")

# --- 4. Main Generation Loop ---
for bench in benchmarks:
    subset = df_master[df_master['name'] == bench].copy()
    if subset.empty: continue

    # A. Sorting Logic
    subset['sweep_type'] = pd.Categorical(
        subset['sweep_type'],
        categories=["Baseline", "Cache Size", "Associativity", "BTB Size", "BHT Size"],
        ordered=True
    )
    subset['sort_val'] = subset.apply(
        lambda row: -1 if row['sweep_type'] == 'Baseline' else get_sort_value(row['config']),
        axis=1
    )
    subset = subset.sort_values(by=['sweep_type', 'sort_val'])

    # B. Apply Descriptive Labels
    subset['pretty_config'] = subset['config'].apply(prettify_config)

    # C. Dynamic Zoom Calculation
    min_score = subset['score'].min()
    max_score = subset['score'].max()
    diff = max_score - min_score
    if diff == 0: diff = max_score * 0.01
    y_min = max(0, min_score - (diff * 0.5))
    y_max = max_score + (diff * 0.5)

    # D. Plotting
    fig, ax1 = plt.subplots(figsize=(11, 7))
    sns.set_theme(style="whitegrid")

    # Bar Chart (Score)
    sns.barplot(
        data=subset, x="pretty_config", y="score", hue="sweep_type",
        palette=palette, dodge=False, ax=ax1, alpha=0.85
    )
    ax1.set_ylim(y_min, y_max)

    # --- UPDATED Y-AXIS LABEL ---
    raw_unit = subset['units'].iloc[0]
    descriptive_label = format_y_label(raw_unit)
    ax1.set_ylabel(descriptive_label, fontsize=12)

    ax1.set_xlabel("")
    ax1.tick_params(axis='x', rotation=70, labelsize=10)

    # Line Chart (IPC)
    ax2 = ax1.twinx()
    sns.pointplot(
        data=subset, x="pretty_config", y="ipc", color="red",
        markers="o", scale=0.7, ax=ax2, linestyles="-"
    )

    # --- UPDATED SECONDARY Y-AXIS LABEL ---
    ax2.set_ylabel(r"Efficiency [IPC]", color="red", fontsize=12)
    ax2.tick_params(axis='y', labelcolor="red")

    # Baseline Reference Line
    base_rows = subset[subset['sweep_type'] == "Baseline"]
    if not base_rows.empty:
        base_val = base_rows['score'].values[0]
        baseline_text = (
            "Baseline Config:\n"
            r"$\bullet$ 4KB L1 Cache" "\n"
            r"$\bullet$ 4-Way Assoc" "\n"
            r"$\bullet$ 16-Entry BTB" "\n"
            r"$\bullet$ 16-Entry BHT"
        )
        ax1.axhline(base_val, color='black', linestyle='--', linewidth=1.5, alpha=0.6, label=baseline_text)

    # --- UPDATED DESCRIPTIVE TITLE ---
    # Using 'Sensitivity Analysis' describes the plot's purpose better than just 'Profile'
    plt.title(f"Microarchitectural Sensitivity Analysis: {bench}", fontsize=16, pad=15)

    # Legend Construction
    handles, labels = ax1.get_legend_handles_labels()
    unique_labels = []
    unique_handles = []
    seen = set()
    base_h, base_l = None, None

    for h, l in zip(handles, labels):
        if "Baseline Config" in l:
            base_h, base_l = h, l
        elif l not in seen:
            seen.add(l)
            unique_labels.append(l)
            unique_handles.append(h)

    if base_h:
        unique_handles.append(base_h)
        unique_labels.append(base_l)

    ax1.legend(
        unique_handles, unique_labels,
        title="Parameters", bbox_to_anchor=(1.12, 1), loc='upper left'
    )

    # E. Explanatory Text Below X-Axis
    plt.figtext(
        0.5, 0.02,
        "Hardware Configuration.",
        ha="center", fontsize=10, style='italic'
    )

    # F. Save
    plt.tight_layout()
    plt.subplots_adjust(bottom=0.2)

    save_path = os.path.join(PLOTS_DIR, f"benchmark_{bench}.png")
    plt.savefig(save_path, bbox_inches='tight')
    plt.close()

print(f"Success! All images saved to: {PLOTS_DIR}")
#+end_src

#+RESULTS:
:results:
#+begin_exampleGenerating publication-ready images for 20 benchmarks...
Success! All images saved to: /home/han4n/cva6_experiments/results/individual_benchmark_profiles
#+end_example
:end:

